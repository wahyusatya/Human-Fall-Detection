{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe3f473-8e59-4b38-93b3-b97997e437e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to generate labels for the training data\n",
    "def generate_labels(train_dir):\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    \n",
    "    # Traverse through each subject folder\n",
    "    for subject in os.listdir(train_dir):\n",
    "        subject_path = os.path.join(train_dir, subject)\n",
    "        \n",
    "        # Check fall and non-fall activities\n",
    "        for activity in ['fall', 'non_fall']:\n",
    "            activity_path = os.path.join(subject_path, activity)\n",
    "            \n",
    "            # Iterate through sub-activities (e.g., backward_falls, forward_falls, etc.)\n",
    "            for sub_activity in os.listdir(activity_path):\n",
    "                sub_activity_path = os.path.join(activity_path, sub_activity)\n",
    "                \n",
    "                # Iterate through each image in the sub-activity folder\n",
    "                for img in os.listdir(sub_activity_path):\n",
    "                    image_paths.append(os.path.join(sub_activity_path, img))\n",
    "                    label = 1 if activity == 'fall' else 0\n",
    "                    labels.append(label)\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "    df.to_csv('datasets/train_labels.csv', index=False)\n",
    "    print(\"Labeling complete. Labels saved to 'train_labels.csv'.\")\n",
    "\n",
    "# Directory of your training data\n",
    "train_directory = 'datasets/train'\n",
    "generate_labels(train_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db16b7d-a39e-4f92-b89d-42a20cc88977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mediapipe as mp\n",
    "\n",
    "class FallDetectionPipeline:\n",
    "    def __init__(self, input_size=(224, 224)):\n",
    "        self.input_size = input_size\n",
    "        self.pose_detector = mp.solutions.pose.Pose(\n",
    "            static_image_mode=True,\n",
    "            model_complexity=1,\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "        \n",
    "    def preprocess_image(self, image_path):\n",
    "        # Read and resize image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, self.input_size)\n",
    "        return image  # Return uint8 image without normalization\n",
    "        \n",
    "    def normalize_image(self, image):\n",
    "        # Normalize image for CNN (separate from MediaPipe preprocessing)\n",
    "        return image.astype(np.float32) / 255.0\n",
    "\n",
    "    def extract_pose_features(self, image):\n",
    "        # Extract pose landmarks using uint8 image\n",
    "        results = self.pose_detector.process(image)  # image should be uint8\n",
    "        features = []\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                features.extend([landmark.x, landmark.y, landmark.z])\n",
    "        else:\n",
    "            features = [0] * (33 * 3)  # 33 landmarks with x,y,z coordinates\n",
    "            \n",
    "        return np.array(features)\n",
    "\n",
    "class FallDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, pipeline):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.pipeline = pipeline\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        # Get uint8 image for pose detection\n",
    "        image = self.pipeline.preprocess_image(image_path)\n",
    "        \n",
    "        # Extract pose features using uint8 image\n",
    "        pose_features = self.pipeline.extract_pose_features(image)\n",
    "        \n",
    "        # Normalize image for CNN\n",
    "        image_normalized = self.pipeline.normalize_image(image)\n",
    "        \n",
    "        # Transform normalized image\n",
    "        image_tensor = self.transform(image_normalized)\n",
    "        \n",
    "        # Convert pose features to tensor\n",
    "        pose_tensor = torch.FloatTensor(pose_features)\n",
    "        \n",
    "        return {\n",
    "            'image': image_tensor,\n",
    "            'pose': pose_tensor,\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class FallDetectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FallDetectionModel, self).__init__()\n",
    "        \n",
    "        # CNN for image features - using recommended weights parameter\n",
    "        self.cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.cnn.fc = nn.Identity()\n",
    "        \n",
    "        # MLP for pose features\n",
    "        self.pose_net = nn.Sequential(\n",
    "            nn.Linear(99, 64),  # 33 landmarks * 3 coordinates\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Combined classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 + 64, 128),  # 512 from ResNet18, 64 from pose_net\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 2)  # 2 classes: fall/non-fall\n",
    "        )\n",
    "\n",
    "    def forward(self, image, pose):\n",
    "        # Extract image features\n",
    "        image_features = self.cnn(image)\n",
    "        \n",
    "        # Process pose features\n",
    "        pose_features = self.pose_net(pose)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat((image_features, pose_features), dim=1)\n",
    "        \n",
    "        # Classify\n",
    "        return self.classifier(combined)\n",
    "\n",
    "def save_model(model, train_history, model_dir='models'):\n",
    "    \"\"\"\n",
    "    Menyimpan model dan history training\n",
    "    \"\"\"\n",
    "    # Buat direktori jika belum ada\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # Generate nama file dengan timestamp dan best val loss\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    best_val_loss = min(train_history['val_loss'])\n",
    "    \n",
    "    model_path = os.path.join(model_dir, \n",
    "                             f'fall_detection_model_{timestamp}_valloss_{best_val_loss:.4f}.pth')\n",
    "    history_path = os.path.join(model_dir, \n",
    "                               f'training_history_{timestamp}_valloss_{best_val_loss:.4f}.csv')\n",
    "    \n",
    "    # Simpan model state\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'train_history': train_history,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'timestamp': timestamp\n",
    "    }, model_path)\n",
    "    \n",
    "    # Simpan history training\n",
    "    pd.DataFrame(train_history).to_csv(history_path, index=False)\n",
    "    \n",
    "    print(f\"\\nModel saved to {model_path}\")\n",
    "    print(f\"Training history saved to {history_path}\")\n",
    "    \n",
    "    return model_path, history_path\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Memuat model yang telah disimpan\n",
    "    \"\"\"\n",
    "    # Inisialisasi model baru\n",
    "    model = FallDetectionModel()\n",
    "    \n",
    "    # Load state dict\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Untuk menyimpan history training\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Inisialisasi best model checkpoint\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "    patience = 5  # Early stopping patience\n",
    "    counter = 0   # Counter untuk early stopping\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            poses = batch['pose'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, poses)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss = train_loss/len(train_loader)\n",
    "        train_acc = 100.*correct/total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                poses = batch['pose'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(images, poses)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        val_acc = 100.*correct/total\n",
    "        \n",
    "        # Simpan metrics\n",
    "        history['epoch'].append(epoch + 1)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # Check if this is the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            best_epoch = epoch + 1\n",
    "            counter = 0  # Reset early stopping counter\n",
    "            print(f'New best model found! (Val Loss: {val_loss:.4f})')\n",
    "        else:\n",
    "            counter += 1  # Increment counter if no improvement\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Time: {epoch_time:.2f}s')\n",
    "        print(f'Best epoch so far: {best_epoch} (Val Loss: {best_val_loss:.4f})')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping triggered! No improvement for {patience} epochs.')\n",
    "            break\n",
    "    \n",
    "    # Load best model before returning\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f'\\nTraining completed. Best model was from epoch {best_epoch} with validation loss: {best_val_loss:.4f}')\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def predict_test_images(model_path, test_dir, pipeline):\n",
    "    \"\"\"\n",
    "    Melakukan prediksi menggunakan model yang telah disimpan\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = load_model(model_path)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    image_paths = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    print(\"Starting predictions...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for img_name in os.listdir(test_dir):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        image_paths.append(img_path)\n",
    "        \n",
    "        # Preprocess image\n",
    "        image = pipeline.preprocess_image(img_path)\n",
    "        pose_features = pipeline.extract_pose_features(image)\n",
    "        image_normalized = pipeline.normalize_image(image)\n",
    "        \n",
    "        # Prepare tensors\n",
    "        image_tensor = transform(image_normalized).unsqueeze(0).to(device)\n",
    "        pose_tensor = torch.FloatTensor(pose_features).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor, pose_tensor)\n",
    "            _, predicted = output.max(1)\n",
    "            predictions.append(predicted.item())\n",
    "    \n",
    "    # Save predictions\n",
    "    results_dir = 'results'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "        \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    predictions_path = os.path.join(results_dir, f'test_predictions_{timestamp}.csv')\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'image_path': image_paths,\n",
    "        'prediction': predictions\n",
    "    })\n",
    "    df.to_csv(predictions_path, index=False)\n",
    "    \n",
    "    print(f\"Predictions completed in {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Results saved to {predictions_path}\")\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Check if we want to train or just predict\n",
    "    model_path = 'models/fall_detection_model.pth'  # path to saved model\n",
    "    mode = input(\"Enter mode (train/predict): \").lower()\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline = FallDetectionPipeline()\n",
    "    \n",
    "    if mode == 'train':\n",
    "        print(\"Starting training mode...\")\n",
    "        \n",
    "        # Load training data\n",
    "        train_df = pd.read_csv('datasets/train_labels.csv')\n",
    "        \n",
    "        # Split into train and validation\n",
    "        train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = FallDataset(train_data['image_path'].values, \n",
    "                                   train_data['label'].values,\n",
    "                                   pipeline)\n",
    "        val_dataset = FallDataset(val_data['image_path'].values,\n",
    "                                 val_data['label'].values,\n",
    "                                 pipeline)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "        \n",
    "        # Initialize and train model\n",
    "        model = FallDetectionModel()\n",
    "        trained_model, history = train_model(model, train_loader, val_loader)\n",
    "        \n",
    "        # Save model and history\n",
    "        model_path, history_path = save_model(trained_model, history)\n",
    "        \n",
    "    elif mode == 'predict':\n",
    "        # Check if model exists\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Error: Model not found at {model_path}\")\n",
    "            print(\"Please train the model first or provide correct model path\")\n",
    "            return\n",
    "            \n",
    "        print(\"Starting prediction mode...\")\n",
    "        # Predict on test images\n",
    "        test_dir = 'datasets/test'\n",
    "        predictions = predict_test_images(model_path, test_dir, pipeline)\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid mode. Please choose 'train' or 'predict'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
